{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "201c60e0",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e13d989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "from ast import literal_eval\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ac5d353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance</th>\n",
       "      <th>hate_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>mentions_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>hate_avg</th>\n",
       "      <th>url_avg</th>\n",
       "      <th>mentions_avg</th>\n",
       "      <th>hashtag_avg</th>\n",
       "      <th>users</th>\n",
       "      <th>...</th>\n",
       "      <th>active_halfyear</th>\n",
       "      <th>active_month</th>\n",
       "      <th>hash_ftr</th>\n",
       "      <th>hash_rej</th>\n",
       "      <th>hash_sen</th>\n",
       "      <th>blocked</th>\n",
       "      <th>users_tr</th>\n",
       "      <th>posts_tr</th>\n",
       "      <th>hate_tr</th>\n",
       "      <th>url_tr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1210mw.com</td>\n",
       "      <td>125436.0</td>\n",
       "      <td>32128.0</td>\n",
       "      <td>46716.0</td>\n",
       "      <td>28156.0</td>\n",
       "      <td>1.410852</td>\n",
       "      <td>0.361362</td>\n",
       "      <td>0.525448</td>\n",
       "      <td>0.316690</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.200937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.075172</td>\n",
       "      <td>5.638288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>434.earth</td>\n",
       "      <td>973.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1.605611</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.919008</td>\n",
       "      <td>0.395041</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.899691</td>\n",
       "      <td>3.837165</td>\n",
       "      <td>3.147885</td>\n",
       "      <td>2.792306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7td.org</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>2447.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>1.056572</td>\n",
       "      <td>0.080532</td>\n",
       "      <td>0.814581</td>\n",
       "      <td>0.073236</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.552463</td>\n",
       "      <td>2.322647</td>\n",
       "      <td>3.833751</td>\n",
       "      <td>2.496333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80percent.social</td>\n",
       "      <td>10561.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>10190.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>1.735009</td>\n",
       "      <td>0.144899</td>\n",
       "      <td>1.674335</td>\n",
       "      <td>0.131614</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.618870</td>\n",
       "      <td>2.872694</td>\n",
       "      <td>4.684007</td>\n",
       "      <td>3.096788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a.nom.pl</td>\n",
       "      <td>2137.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1.518834</td>\n",
       "      <td>0.101635</td>\n",
       "      <td>0.956615</td>\n",
       "      <td>0.115932</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.661001</td>\n",
       "      <td>3.530044</td>\n",
       "      <td>3.588950</td>\n",
       "      <td>2.286771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           instance  hate_count  url_count  mentions_count  hashtag_count  \\\n",
       "0        1210mw.com    125436.0    32128.0         46716.0        28156.0   \n",
       "1         434.earth       973.0      474.0           556.0          239.0   \n",
       "2           7td.org      3175.0      242.0          2447.0          220.0   \n",
       "3  80percent.social     10561.0      882.0         10190.0          801.0   \n",
       "4          a.nom.pl      2137.0      143.0          1345.0          163.0   \n",
       "\n",
       "   hate_avg   url_avg  mentions_avg  hashtag_avg  users  ...  active_halfyear  \\\n",
       "0  1.410852  0.361362      0.525448     0.316690    3.0  ...              0.0   \n",
       "1  1.605611  0.782178      0.919008     0.395041   47.0  ...              0.0   \n",
       "2  1.056572  0.080532      0.814581     0.073236   14.0  ...              0.0   \n",
       "3  1.735009  0.144899      1.674335     0.131614   18.0  ...              0.0   \n",
       "4  1.518834  0.101635      0.956615     0.115932   21.0  ...              0.0   \n",
       "\n",
       "   active_month  hash_ftr  hash_rej  hash_sen  blocked  users_tr  posts_tr  \\\n",
       "0           0.0       0.0       0.0       1.0        0  1.200937  1.000000   \n",
       "1           0.0       0.0       0.0       0.0        1  1.899691  3.837165   \n",
       "2           0.0       0.0       0.0       1.0        1  1.552463  2.322647   \n",
       "3           0.0       0.0       0.0       0.0        1  1.618870  2.872694   \n",
       "4           0.0       0.0       0.0       1.0        0  1.661001  3.530044   \n",
       "\n",
       "    hate_tr    url_tr  \n",
       "0  7.075172  5.638288  \n",
       "1  3.147885  2.792306  \n",
       "2  3.833751  2.496333  \n",
       "3  4.684007  3.096788  \n",
       "4  3.588950  2.286771  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get features\n",
    "\n",
    "data = pd.read_csv('dataset/features.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c0788d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select features\n",
    "data = data[['users', 'posts', 'hate_count', 'url_count', 'mentions_count', 'hate_avg', 'url_avg', 'hashtag_avg',\n",
    "                'mentions_avg', 'posts_tr', 'reject', 'nsfw', 'media_removal', 'fed_time_rem', 'reject_deletes',\n",
    "                 'quaran_inst', 'blocked']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "393d0457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    " #train data\n",
    "features = data.drop('blocked', axis=1)\n",
    "labels = data['blocked']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "data\n",
    "\n",
    "# check splits\n",
    "for dataset in [y_train, y_test]:\n",
    "    print(round(len(dataset) / len(labels), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6db192e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "\n",
    "X_train.to_csv('/Users/ishaku/Documents/PhD/phd_work/algorithms_loop_www/train_features.csv', index=False)\n",
    "X_test.to_csv('/Users/ishaku/Documents/PhD/phd_work/algorithms_loop_www/test_features.csv', index=False)\n",
    "\n",
    "y_train.to_csv('/Users/ishaku/Documents/PhD/phd_work/algorithms_loop_www/train_labels.csv', index=False)\n",
    "y_test.to_csv('/Users/ishaku/Documents/PhD/phd_work/algorithms_loop_www/test_labels.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5dbeb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f21c217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e036adfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'C': 0.1}\n",
      "\n",
      "0.777 (+/-0.021) for {'C': 0.001}\n",
      "0.773 (+/-0.023) for {'C': 0.01}\n",
      "0.778 (+/-0.025) for {'C': 0.1}\n",
      "0.778 (+/-0.025) for {'C': 1}\n",
      "0.778 (+/-0.025) for {'C': 10}\n",
      "0.775 (+/-0.03) for {'C': 100}\n",
      "0.776 (+/-0.022) for {'C': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/ishaku/Documents/PhD/phd_work/algorithms_loop_www/LR_model.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "LogisticRegression()\n",
    "\n",
    "#Load data\n",
    "\n",
    "tr_features = pd.read_csv('/Users/ishaku/Documents/PhD/phd_work/algorithms_loop_www/train_features.csv')\n",
    "tr_labels = pd.read_csv('/Users/ishaku/Documents/PhD/phd_work/algorithms_loop_www/train_labels.csv')\n",
    "\n",
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))\n",
    "\n",
    "lr = LogisticRegression()\n",
    "parameters = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(lr, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)\n",
    "\n",
    "# Write pickled model\n",
    "joblib.dump(cv.best_estimator_, '/Users/ishaku/Documents/PhD/phd_work/algorithms_loop_www/LR_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22b57967",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdf1a0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor()\n",
      "MLPClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/ishaku/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n",
      "\n",
      "0.625 (+/-0.198) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant'}\n",
      "0.664 (+/-0.164) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "0.66 (+/-0.107) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive'}\n",
      "0.619 (+/-0.122) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "0.612 (+/-0.143) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "0.672 (+/-0.155) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive'}\n",
      "0.68 (+/-0.108) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "0.6 (+/-0.079) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}\n",
      "0.651 (+/-0.127) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n",
      "0.76 (+/-0.018) for {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant'}\n",
      "0.768 (+/-0.036) for {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "0.753 (+/-0.045) for {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive'}\n",
      "0.761 (+/-0.047) for {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "0.771 (+/-0.037) for {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "0.772 (+/-0.025) for {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive'}\n",
      "0.758 (+/-0.056) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "0.772 (+/-0.047) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}\n",
      "0.779 (+/-0.015) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n",
      "0.752 (+/-0.009) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant'}\n",
      "0.763 (+/-0.027) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "0.769 (+/-0.031) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive'}\n",
      "0.769 (+/-0.028) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "0.768 (+/-0.022) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "0.775 (+/-0.01) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive'}\n",
      "0.773 (+/-0.041) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "0.768 (+/-0.034) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}\n",
      "0.779 (+/-0.023) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/ishaku/Documents/PhD/phd_work/algorithms_loop_www/MLP_model.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(MLPRegressor())\n",
    "print(MLPClassifier())\n",
    "\n",
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))\n",
    "\n",
    "\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(10,), (50,), (100,)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive']\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(mlp, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)\n",
    "\n",
    "# Write pickled model\n",
    "joblib.dump(cv.best_estimator_, '/Users/ishaku/Documents/PhD/phd_work/algorithms_loop_www/MLP_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0851d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "885ef07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n",
      "RandomForestRegressor()\n",
      "BEST PARAMS: {'max_depth': 8, 'n_estimators': 250}\n",
      "\n",
      "0.828 (+/-0.073) for {'max_depth': 2, 'n_estimators': 5}\n",
      "0.825 (+/-0.05) for {'max_depth': 2, 'n_estimators': 50}\n",
      "0.83 (+/-0.05) for {'max_depth': 2, 'n_estimators': 250}\n",
      "0.833 (+/-0.045) for {'max_depth': 4, 'n_estimators': 5}\n",
      "0.841 (+/-0.052) for {'max_depth': 4, 'n_estimators': 50}\n",
      "0.847 (+/-0.053) for {'max_depth': 4, 'n_estimators': 250}\n",
      "0.811 (+/-0.023) for {'max_depth': 8, 'n_estimators': 5}\n",
      "0.841 (+/-0.048) for {'max_depth': 8, 'n_estimators': 50}\n",
      "0.848 (+/-0.042) for {'max_depth': 8, 'n_estimators': 250}\n",
      "0.805 (+/-0.015) for {'max_depth': 16, 'n_estimators': 5}\n",
      "0.845 (+/-0.054) for {'max_depth': 16, 'n_estimators': 50}\n",
      "0.84 (+/-0.04) for {'max_depth': 16, 'n_estimators': 250}\n",
      "0.817 (+/-0.027) for {'max_depth': 32, 'n_estimators': 5}\n",
      "0.848 (+/-0.043) for {'max_depth': 32, 'n_estimators': 50}\n",
      "0.845 (+/-0.044) for {'max_depth': 32, 'n_estimators': 250}\n",
      "0.824 (+/-0.052) for {'max_depth': None, 'n_estimators': 5}\n",
      "0.84 (+/-0.071) for {'max_depth': None, 'n_estimators': 50}\n",
      "0.843 (+/-0.038) for {'max_depth': None, 'n_estimators': 250}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/ishaku/Documents/PhD/phd_work/algorithms_loop_www/RF_model.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(RandomForestClassifier())\n",
    "print(RandomForestRegressor())\n",
    "\n",
    "\n",
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250],\n",
    "    'max_depth': [2, 4, 8, 16, 32, None]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(rf, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)\n",
    "\n",
    "# Write pickled model\n",
    "joblib.dump(cv.best_estimator_, '/Users/ishaku/Documents/PhD/phd_work/algorithms_loop_www/RF_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab5374af",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Gradient boosted trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63f22706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier()\n",
      "GradientBoostingRegressor()\n",
      "BEST PARAMS: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "\n",
      "0.753 (+/-0.005) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.753 (+/-0.005) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.834 (+/-0.07) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.847 (+/-0.052) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.753 (+/-0.005) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.777 (+/-0.034) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.845 (+/-0.044) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.847 (+/-0.05) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.753 (+/-0.005) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.814 (+/-0.025) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.845 (+/-0.035) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.836 (+/-0.047) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.753 (+/-0.005) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.836 (+/-0.035) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.834 (+/-0.02) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.828 (+/-0.034) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.753 (+/-0.005) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.839 (+/-0.02) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.83 (+/-0.025) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.836 (+/-0.028) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.753 (+/-0.005) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.841 (+/-0.057) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.836 (+/-0.047) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.826 (+/-0.062) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.787 (+/-0.026) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.833 (+/-0.047) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.826 (+/-0.041) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.818 (+/-0.064) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.818 (+/-0.026) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.837 (+/-0.043) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.834 (+/-0.044) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.828 (+/-0.043) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.836 (+/-0.021) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.832 (+/-0.033) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.841 (+/-0.038) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.829 (+/-0.062) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.83 (+/-0.031) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.826 (+/-0.037) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.826 (+/-0.055) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.824 (+/-0.06) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.825 (+/-0.052) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.813 (+/-0.087) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.799 (+/-0.066) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.795 (+/-0.071) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.811 (+/-0.045) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.799 (+/-0.087) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.806 (+/-0.071) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.81 (+/-0.075) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.806 (+/-0.06) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.82 (+/-0.033) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.813 (+/-0.041) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.826 (+/-0.042) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.822 (+/-0.058) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.829 (+/-0.049) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.84 (+/-0.055) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.821 (+/-0.075) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.83 (+/-0.028) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.837 (+/-0.059) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.836 (+/-0.038) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.836 (+/-0.051) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.217 (+/-0.049) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.217 (+/-0.049) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.217 (+/-0.049) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.217 (+/-0.049) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.324 (+/-0.443) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.324 (+/-0.443) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.324 (+/-0.443) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.324 (+/-0.443) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.472 (+/-0.366) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.479 (+/-0.415) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.437 (+/-0.415) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.468 (+/-0.41) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.507 (+/-0.275) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.489 (+/-0.238) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.491 (+/-0.357) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.432 (+/-0.214) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.736 (+/-0.256) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.709 (+/-0.326) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.662 (+/-0.334) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.711 (+/-0.335) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.247 (+/-0.005) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.247 (+/-0.005) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.247 (+/-0.005) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.247 (+/-0.005) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.231 (+/-0.076) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.227 (+/-0.083) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.228 (+/-0.076) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.231 (+/-0.076) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.296 (+/-0.055) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.302 (+/-0.073) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.319 (+/-0.072) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.303 (+/-0.079) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.399 (+/-0.145) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.467 (+/-0.301) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.373 (+/-0.211) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.388 (+/-0.136) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.678 (+/-0.137) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.773 (+/-0.086) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.609 (+/-0.208) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.73 (+/-0.164) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 500}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/ishaku/Documents/PhD/phd_work/algorithms_loop_www/GB_model.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(GradientBoostingClassifier())\n",
    "print(GradientBoostingRegressor())\n",
    "\n",
    "\n",
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))\n",
    "\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250, 500],\n",
    "    'max_depth': [1, 3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(gb, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)\n",
    "\n",
    "# Write pickled model\n",
    "joblib.dump(cv.best_estimator_, '/Users/ishaku/Documents/PhD/phd_work/algorithms_loop_www/GB_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77cd10d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare model results\n",
    "\n",
    "te_features = pd.read_csv('/Users/ishaku/Documents/PhD/phd_work/algorithms_loop_www/test_features.csv')\n",
    "te_labels = pd.read_csv('/Users/ishaku/Documents/PhD/phd_work/algorithms_loop_www/test_labels.csv')\n",
    "\n",
    "models = {}\n",
    "\n",
    "for mdl in ['LR', 'MLP', 'RF', 'GB']:\n",
    "    models[mdl] = joblib.load('/Users/ishaku/Documents/PhD/phd_work/algorithms_loop_www/{}_model.pkl'.format(mdl))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cf890b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR -- \tAccuracy: 0.865 / Precision: 0.857 / Recall: 0.343 / f1: 0.49 / Latency: 0.8ms\n",
      "MLP -- \tAccuracy: 0.816 / Precision: 0.52 / Recall: 0.371 / f1: 0.433 / Latency: 1.0ms\n",
      "RF -- \tAccuracy: 0.919 / Precision: 0.857 / Recall: 0.686 / f1: 0.762 / Latency: 14.7ms\n",
      "GB -- \tAccuracy: 0.897 / Precision: 0.722 / Recall: 0.743 / f1: 0.732 / Latency: 1.6ms\n",
      "  name  accuracy  precision  recall     f1  time\n",
      "0   LR     0.865      0.857   0.343  0.490   0.8\n",
      "1  MLP     0.816      0.520   0.371  0.433   1.0\n",
      "2   RF     0.919      0.857   0.686  0.762  14.7\n",
      "3   GB     0.897      0.722   0.743  0.732   1.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_model(name, model, features, labels):\n",
    "    start = time()\n",
    "    pred = model.predict(features)\n",
    "    end = time()\n",
    "    accuracy = round(accuracy_score(labels, pred), 3)\n",
    "    precision = round(precision_score(labels, pred), 3)\n",
    "    recall = round(recall_score(labels, pred), 3)\n",
    "    f1 = round(f1_score(labels, pred), 3)\n",
    "    print('{} -- \\tAccuracy: {} / Precision: {} / Recall: {} / f1: {} / Latency: {}ms'.format(name,\n",
    "                                                                                     accuracy,\n",
    "                                                                                     precision,\n",
    "                                                                                     recall,\n",
    "                                                                                     f1,\n",
    "                                                                                     round((end - start)*1000, 1)))\n",
    "    return name, accuracy, precision, recall, f1, round((end - start)*1000, 1)\n",
    "\n",
    "\n",
    "str_name, str_accuracy, str_precision, str_recall, str_f1, str_time = [], [], [], [], [], []\n",
    "\n",
    "for name, mdl in models.items():\n",
    "    x1, x2, x3, x4, x5, x6 = evaluate_model(name, mdl, te_features, te_labels)\n",
    "    str_name.append(x1)\n",
    "    str_accuracy.append(x2)\n",
    "    str_precision.append(x3)\n",
    "    str_recall.append(x4)\n",
    "    str_f1.append(x5)\n",
    "    str_time.append(x6)\n",
    "df = pd.DataFrame({'name': str_name, 'accuracy': str_accuracy, 'precision': str_precision, 'recall': str_recall, 'f1': str_f1, 'time': str_time})\n",
    "\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0fe7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
